{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "\n",
    "**The** python library for numerical computing is numpy. The main data object is the n-dimensional array; numpy functions create and manipulate n-d arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# create a 6x6 array filled with zeros\n",
    "shape = (6, 6)\n",
    "array = np.zeros(shape)\n",
    "print array\n",
    "print type(array)\n",
    "print\n",
    "\n",
    "# the most important attributes of a numpy array are its shape and its dtype\n",
    "print array.shape\n",
    "print array.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2d numpy arrays are indexed as [row, column]\n",
    "array[1, 3] = 1\n",
    "print array\n",
    "print\n",
    "\n",
    "# you can use fancy index slicing on numpy arrays. See http://docs.scipy.org/doc/numpy-1.10.1/user/basics.indexing.html\n",
    "array[1::2, :] = 2\n",
    "array[::2, -1] = 3\n",
    "print array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to create a mask, use comparisons directly on the array\n",
    "# this creates an array of boolean values\n",
    "mask = array==3\n",
    "print mask\n",
    "print\n",
    "\n",
    "# a mask array can be used to index arrays (including images)\n",
    "array[mask] += 1\n",
    "print array\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is almost never necessary to access array elements individually -- use library functions, algebraic expressions, and masks to manipulate images whenever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numpy has a ton of functions that are useful for manipulating and querying arrays\n",
    "print np.fliplr(array)\n",
    "print\n",
    "print np.mean(array)\n",
    "print np.std(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# imread loads many different image formats as numpy arrays\n",
    "im = plt.imread('sample-images/peppers.png')\n",
    "print type(im), im.shape, im.dtype\n",
    "print \n",
    "\n",
    "plt.imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dimension (of length 3) represents the channels in (red, green, blue) format. Grayscale images may only have 2 dimensions -- there is no channel dimension. Some image formats have an extra alpha channel, which specifies the transparency of each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_imshow(im, title=None):\n",
    "    plt.figure()\n",
    "    plt.imshow(im, cmap='gray', interpolation='none')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def imshow_overlay(im, mask, alpha=0.5, color='red', **kwargs):\n",
    "    \"\"\"Show semi-transparent red mask over an image\"\"\"\n",
    "    mask = mask > 0\n",
    "    mask = np.ma.masked_where(~mask, mask)        \n",
    "    plt.imshow(im, **kwargs)\n",
    "    plt.imshow(mask, alpha=alpha, cmap=ListedColormap([color]))\n",
    "\n",
    "\n",
    "my_imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manipulate image pixels in the same way as any numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im[:100, :200, :] = 0\n",
    "my_imshow(im)\n",
    "plt.axis('on');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = plt.imread('sample-images/peppers.png')\n",
    "red = im[..., 0]\n",
    "green = im[..., 1]\n",
    "\n",
    "my_imshow(red, 'red channel')\n",
    "plt.show()\n",
    "\n",
    "my_imshow(green, 'green channel')\n",
    "\n",
    "im[:,:,0] = 0\n",
    "my_imshow(im, 'red channel zeroed out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering: Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "from scipy.ndimage.filters import convolve\n",
    "from skimage import color\n",
    "\n",
    "im = plt.imread('sample-images/peppers.png')\n",
    "gray_im = color.rgb2gray(im)\n",
    "\n",
    "\n",
    "# uniform blur\n",
    "kern_sz = 15\n",
    "kernel = np.ones((kern_sz,kern_sz))/kern_sz**2\n",
    "uniform_blurred = convolve(gray_im, kernel)\n",
    "\n",
    "my_imshow(gray_im, 'original image')\n",
    "my_imshow(uniform_blurred, 'uniform blur, kernel size %i' % kern_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import gaussian\n",
    "\n",
    "# gaussian blur\n",
    "kern_sz = 15\n",
    "sigma = 3\n",
    "kernel_1d = gaussian(kern_sz, sigma)\n",
    "kernel = np.outer(kernel_1d, kernel_1d)\n",
    "gauss_blurred = convolve(gray_im, kernel)\n",
    "\n",
    "plt.plot(kernel_1d, 'o-')\n",
    "my_imshow(kernel, 'kernel')\n",
    "my_imshow(gray_im, 'original image')\n",
    "my_imshow(gauss_blurred, 'uniform blur, kernel size %i, sigma %.2f' % (kern_sz, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Both the uniform blur and the gaussian blur have efficient library implementations. In the above examples, I used explicit convolution calls to illustrate how these library functions work \"under the hood\". In production, you should use the library functions [`uniform filter`](http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.ndimage.filters.uniform_filter.html) and [`gaussian_filter`](http://scikit-image.org/docs/dev/api/skimage.filters.html#gaussian-filter) to do blurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering: Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "grad_x = filters.sobel_h(gray_im)\n",
    "grad_y = filters.sobel_v(gray_im)\n",
    "grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
    "\n",
    "my_imshow(gray_im, 'original image')\n",
    "my_imshow(grad_x, 'y gradient (horizontal edges)')\n",
    "my_imshow(grad_y, 'x gradient (vertical edges)')\n",
    "my_imshow(grad_mag, 'gradient magnitude (edge strength)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering: Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# difference of gaussians\n",
    "\n",
    "sigma1 = 7.\n",
    "sigma2 = 2.5*sigma1\n",
    "kern_sz = 3*sigma2\n",
    "\n",
    "x, y = np.mgrid[-kern_sz/2+1:kern_sz/2+1, -kern_sz/2+1:kern_sz/2+1]\n",
    "rsqr = x**2 + y**2\n",
    "gaussian1 = np.exp(-rsqr/sigma1**2)/sigma1\n",
    "gaussian2 = np.exp(-rsqr/sigma2**2)/sigma2\n",
    "dog_kern = gaussian1 - gaussian2\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dog_kern[:, kern_sz/2])\n",
    "\n",
    "my_imshow(dog_kern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve  # fftconvolve is usually much faster than plain convolve (they do the same thing)\n",
    "\n",
    "im = plt.imread('sample-images/butterfly.png')\n",
    "gray_im = color.rgb2gray(im)\n",
    "\n",
    "blob_im = fftconvolve(gray_im, dog_kern, mode='valid')\n",
    "\n",
    "my_imshow(gray_im)\n",
    "my_imshow(blob_im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = plt.imread('sample-images/lena.png')\n",
    "gray_im = color.rgb2gray(im)\n",
    "\n",
    "my_imshow(gray_im)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(gray_im.ravel(), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use otsu's algorithm to select threshold\n",
    "thresh = filters.threshold_otsu(gray_im)\n",
    "thresholded = gray_im > thresh\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(gray_im.ravel(), bins=100);\n",
    "plt.plot([thresh, thresh], [0, 6000], linewidth=3, color='r');\n",
    "\n",
    "my_imshow(thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### dark on bright background\n",
    "im = plt.imread('sample-images/coins.png')\n",
    "gray_im = color.rgb2gray(im)\n",
    "thresh = filters.threshold_otsu(gray_im)\n",
    "coins = gray_im < thresh  # this is now a less-than operator\n",
    "\n",
    "my_imshow(gray_im, 'original image')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(gray_im.ravel(), bins=100);\n",
    "plt.plot([thresh, thresh], [0, 6000], linewidth=3, color='r');\n",
    "\n",
    "my_imshow(coins, 'thresholded image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from skimage.morphology import disk\n",
    "\n",
    "\n",
    "dilated = morphology.binary_dilation(coins, disk(5))\n",
    "\n",
    "\n",
    "# dilation\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(coins, cmap='gray', interpolation='none')\n",
    "plt.title('original')\n",
    "plt.axis('off');\n",
    "plt.subplot(122)\n",
    "plt.imshow(dilated, cmap='gray', interpolation='none')\n",
    "plt.title('dilated')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eroded = morphology.binary_erosion(coins, disk(5))\n",
    "\n",
    "# erosion\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(coins, cmap='gray', interpolation='none')\n",
    "plt.title('original')\n",
    "plt.axis('off');\n",
    "plt.subplot(122)\n",
    "plt.imshow(eroded, cmap='gray', interpolation='none')\n",
    "plt.title('eroded')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opened = morphology.binary_opening(coins, disk(10))\n",
    "\n",
    "# opening\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(coins, cmap='gray', interpolation='none')\n",
    "plt.title('original')\n",
    "plt.axis('off');\n",
    "plt.subplot(122)\n",
    "plt.imshow(opened, cmap='gray', interpolation='none')\n",
    "plt.title('opened')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closed = morphology.binary_closing(coins, disk(5))\n",
    "\n",
    "# closing\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(coins, cmap='gray', interpolation='none')\n",
    "plt.title('original')\n",
    "plt.axis('off');\n",
    "plt.subplot(122)\n",
    "plt.imshow(closed, cmap='gray', interpolation='none')\n",
    "plt.title('closing')\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "separated_coins = morphology.binary_erosion(closed, disk(20))\n",
    "plt.figure()\n",
    "plt.imshow(separated_coins, cmap='gray', interpolation='none')\n",
    "plt.title('separated coins')\n",
    "plt.axis('off')\n",
    "\n",
    "labelled_coins = measure.label(separated_coins)\n",
    "plt.figure()\n",
    "plt.imshow(labelled_coins, cmap='jet', interpolation='none')\n",
    "plt.title('labelled coins')\n",
    "plt.axis('off')\n",
    "\n",
    "num_coins = len(np.unique(labelled_coins))-1  # subtract 1 b/c background is labelled 0\n",
    "print 'number of coins: %i' % num_coins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worked Example: Segmentation\n",
    "\n",
    "As an example of a typical image processing problem, we will segment the following image of bacteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = plt.imread('sample-images/caulobacter.png')\n",
    "print 'original image shape:', im.shape\n",
    "print 'alpha channel intensity: %.2f +- %.2f' % (np.mean(im[:,:,-1]), np.std(im[:,:,-1]))\n",
    "\n",
    "plt.imshow(im, origin='lower', cmap='gray');\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, convert from color (4 channel, actually) to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "\n",
    "# convert to gray \n",
    "gray_im = color.rgb2gray(im)\n",
    "print 'grayscale image shape:', gray_im.shape\n",
    "\n",
    "plt.imshow(gray_im, origin='lower', cmap='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blur slightly to reduce noise. (This isn't strictly necessary in this case, since it's a fairly high-quality image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "blurred_im = filters.gaussian_filter(gray_im, sigma=3)\n",
    "plt.imshow(blurred_im, origin='lower', cmap='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the image is suitable pre-processed, we can threshold it to convert it to a cell mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh = 0.3\n",
    "mask = gray_im < thresh\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(mask, origin='lower', cmap='gray');\n",
    "plt.title('mask from original grayscale image')\n",
    "plt.axis('off');\n",
    "\n",
    "\n",
    "thresh = 0.3\n",
    "blurred_mask = blurred_im < thresh\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blurred_mask, origin='lower', cmap='gray');\n",
    "plt.title('mask from blurred grayscale image')\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary images are manipulated with *morphological operations*. Morphological operations allow us to expand the white regions, shrink the white regions, fill in holes, and more. In this case, we simply want to remove the tiny dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "blurred_mask_clean = morphology.remove_small_objects(blurred_mask, min_size=150)\n",
    "\n",
    "plt.imshow(blurred_mask_clean, origin='lower', cmap='gray');\n",
    "plt.title('blurred image mask with small object removed')\n",
    "plt.axis('off');\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blurred_mask - blurred_mask_clean, origin='lower', cmap='gray');\n",
    "plt.title('removed small objects')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the cells are touching, so they appear as one object, but we would like to identify them as separate objects. This is a very common problem in segmentation problems (noteably cell tracking). A common approach is to perform a *distance* transform, followed by a *watershed segmentation*.\n",
    "\n",
    "The distance transform converts a binary mask (black-and-white image) into a floating point image (grayscale image) of the same size. Each pixel in the distance transform represents the *distance of that pixel from the nearest black point in the mask*. Thus, the brighest points in the distance transform are the points that are furthest from object boundaries. An example will help clarify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "\n",
    "distance_im = ndi.distance_transform_edt(blurred_mask_clean)\n",
    "print 'distance transform:', distance_im.shape, distance_im.dtype\n",
    "\n",
    "plt.imshow(distance_im, origin='lower', cmap='gray')\n",
    "plt.title('distance transform of mask')\n",
    "plt.axis('off');\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blurred_mask_clean[850:950, 300:400], origin='lower', cmap='gray', interpolation='none')\n",
    "plt.title('mask showing 2 overlapping cells')\n",
    "plt.axis('off');\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(distance_im[850:950, 300:400], origin='lower', cmap='gray', interpolation='none')\n",
    "plt.title('distance transform of above')\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we've done everything right, the peaks of the distance transform image represent the centers of each cell (including those that overlap). We label each separate peak with a unique integer with `skimage.measure.label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import feature, measure\n",
    "\n",
    "peaks_im = feature.peak_local_max(distance_im, indices=False)\n",
    "\n",
    "plt.figure()\n",
    "imshow_overlay(distance_im[850:950, 300:400], peaks_im[850:950, 300:400], alpha=1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "markers_im = measure.label(peaks_im)\n",
    "labelled_cell_im = morphology.watershed(-distance_im, markers_im, mask=blurred_mask_clean)\n",
    "\n",
    "plt.imshow(labelled_cell_im, origin='lower', cmap='jet')\n",
    "plt.title('labelled cells')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blurred_mask_clean[850:950, 300:400], origin='lower', cmap='gray', interpolation='none')\n",
    "plt.title('mask of overlapping cells')\n",
    "plt.axis('off');\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "random_colors = matplotlib.colors.ListedColormap (np.random.rand ( 256,3))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(labelled_cell_im[850:950, 300:400], origin='lower', cmap=random_colors, interpolation='none')\n",
    "plt.title('labelled')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
