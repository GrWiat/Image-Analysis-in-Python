{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "\n",
    "**The** python library for numerical computing is numpy. The main data object is the n-dimensional array; numpy functions create and manipulate n-d arrays. Images in python are invariably represented as n-d arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# create a 6x6 array filled with zeros\n",
    "shape = (6, 6)\n",
    "array = np.zeros(shape)\n",
    "print array\n",
    "print type(array)\n",
    "print\n",
    "\n",
    "# the most important attributes of a numpy array are its shape and its dtype\n",
    "print array.shape\n",
    "print array.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2d numpy arrays are indexed as [row, column]\n",
    "array[1, 3] = 1\n",
    "print array\n",
    "print\n",
    "\n",
    "# you can use fancy index slicing on numpy arrays. See http://docs.scipy.org/doc/numpy-1.10.1/user/basics.indexing.html\n",
    "array[1::2, :] = 2\n",
    "array[::2, -1] = 3\n",
    "print array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to create a mask, use comparisons directly on the array\n",
    "# this creates an array of boolean values\n",
    "mask = array==3\n",
    "print mask\n",
    "print\n",
    "\n",
    "# a mask array can be used to index arrays (including images)\n",
    "array[mask] += 1\n",
    "print array\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it rarely necessary to access array elements individually. You should use library functions, algebraic expressions, and masks to manipulate images whenever possible. This will usually be faster, more concise, and easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# don't do this\n",
    "for row in range(array.shape[0]):\n",
    "    for col in range(array.shape[1]):\n",
    "        if mask[row, col]:\n",
    "            array[row, col] = -1\n",
    "\n",
    "# instead to this\n",
    "array[mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numpy has a ton of functions that are useful for manipulating and querying arrays\n",
    "print np.fliplr(array)\n",
    "print\n",
    "print np.mean(array)\n",
    "print np.std(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# imread loads many different image formats as numpy arrays\n",
    "im = plt.imread('sample-images/peppers.png')\n",
    "print type(im), im.shape, im.dtype\n",
    "print \n",
    "\n",
    "plt.imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dimension (of length 3) represents the channels in (red, green, blue) format. Grayscale images may only have 2 dimensions -- there is no channel dimension. Some image formats have an extra alpha channel, which specifies the transparency of each pixel.\n",
    "\n",
    "Note that some of the matplotlib defaults are stupid. For example, `imshow` will display a single-channel grayscale image with false colors, which is rarely what you want. Here I define a custom function to wrap `plt.imshow`. If you find yourself changing matplotlib defaults a lot, you can put your preferences in a `matplotlibrc` file as explained [here](http://matplotlib.org/users/customizing.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_imshow(im, title=None, **kwargs):\n",
    "    if 'cmap' not in kwargs:\n",
    "        kwargs['cmap'] = 'gray'\n",
    "    plt.figure()\n",
    "    plt.imshow(im, interpolation='none', **kwargs)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "my_imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manipulate image pixels in the same way as any numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im[:100, :200, :] = 0\n",
    "my_imshow(im)\n",
    "plt.axis('on');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = plt.imread('sample-images/peppers.png')\n",
    "red = im[..., 0]\n",
    "green = im[..., 1]  # note the ... syntax. This covers \"all the dimensions except the last one\"\n",
    "\n",
    "my_imshow(red, 'red channel')\n",
    "plt.show()\n",
    "\n",
    "my_imshow(green, 'green channel')\n",
    "\n",
    "im[:,:,0] = 0\n",
    "my_imshow(im, 'red channel zeroed out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering: Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "from scipy.ndimage.filters import convolve\n",
    "from skimage import color\n",
    "\n",
    "im = plt.imread('sample-images/peppers.png')\n",
    "gray_im = color.rgb2gray(im)\n",
    "\n",
    "\n",
    "# uniform blur\n",
    "kern_sz = 15\n",
    "kernel = np.ones((kern_sz,kern_sz))/kern_sz**2  # a uniform filter will produce a simple average (mean)\n",
    "uniform_blurred = convolve(gray_im, kernel)\n",
    "\n",
    "my_imshow(gray_im, 'original image')\n",
    "my_imshow(uniform_blurred, 'uniform blur, kernel size %i' % kern_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import gaussian\n",
    "\n",
    "# gaussian blur\n",
    "kern_sz = 25\n",
    "sigma = 4\n",
    "kernel_1d = gaussian(kern_sz, sigma)\n",
    "kernel = np.outer(kernel_1d, kernel_1d)\n",
    "gauss_blurred = convolve(gray_im, kernel)\n",
    "\n",
    "plt.plot(kernel_1d, 'o-')\n",
    "my_imshow(kernel, 'kernel')\n",
    "my_imshow(gray_im, 'original image')\n",
    "my_imshow(gauss_blurred, 'gaussian blur, kernel size %i, sigma %.2f' % (kern_sz, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Both the uniform blur and the gaussian blur have efficient library implementations. In the above examples, I used explicit convolution calls to illustrate how these library functions work \"under the hood\". In production, you should use the library functions [`uniform filter`](http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.ndimage.filters.uniform_filter.html) and [`gaussian_filter`](http://scikit-image.org/docs/dev/api/skimage.filters.html#gaussian-filter) to do blurring. [`scipy.ndimage`](http://docs.scipy.org/doc/scipy/reference/ndimage.html) also has a number of useful filtering functions which will work on 3D images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering: Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "grad_x = filters.sobel_h(gray_im)\n",
    "grad_y = filters.sobel_v(gray_im)\n",
    "grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
    "\n",
    "my_imshow(gray_im, 'original image')\n",
    "my_imshow(grad_x, 'y gradient (horizontal edges)')\n",
    "my_imshow(grad_y, 'x gradient (vertical edges)')\n",
    "my_imshow(grad_mag, 'gradient magnitude (edge strength)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering: Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# difference of gaussians\n",
    "\n",
    "sigma1 = 7.\n",
    "sigma2 = 2.5*sigma1\n",
    "kern_sz = 3*sigma2\n",
    "\n",
    "x, y = np.mgrid[-kern_sz/2+1:kern_sz/2+1, -kern_sz/2+1:kern_sz/2+1]\n",
    "rsqr = x**2 + y**2\n",
    "gaussian1 = np.exp(-rsqr/sigma1**2)/sigma1\n",
    "gaussian2 = np.exp(-rsqr/sigma2**2)/sigma2\n",
    "dog_kern = gaussian1 - gaussian2\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dog_kern[:, kern_sz/2])\n",
    "\n",
    "my_imshow(dog_kern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve  # fftconvolve is usually much faster than plain convolve (they do the same thing)\n",
    "\n",
    "im = plt.imread('sample-images/butterfly.png')\n",
    "gray_im = color.rgb2gray(im)\n",
    "\n",
    "blob_im = fftconvolve(gray_im, dog_kern, mode='valid')\n",
    "\n",
    "my_imshow(gray_im)\n",
    "my_imshow(blob_im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = plt.imread('sample-images/lena.png')\n",
    "gray_im = color.rgb2gray(im)\n",
    "\n",
    "my_imshow(gray_im)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(gray_im.ravel(), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use otsu's algorithm to select threshold\n",
    "thresh = filters.threshold_otsu(gray_im)\n",
    "thresholded = gray_im > thresh\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(gray_im.ravel(), bins=100);\n",
    "plt.plot([thresh, thresh], [0, 6000], linewidth=3, color='r');\n",
    "\n",
    "my_imshow(thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### dark on bright background\n",
    "im = plt.imread('sample-images/coins.png')\n",
    "gray_im = color.rgb2gray(im)\n",
    "thresh = filters.threshold_otsu(gray_im)\n",
    "coins = gray_im < thresh  # this is now a less-than operator\n",
    "\n",
    "my_imshow(gray_im, 'original image')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(gray_im.ravel(), bins=100);\n",
    "plt.plot([thresh, thresh], [0, 6000], linewidth=3, color='r');\n",
    "\n",
    "my_imshow(coins, 'thresholded image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from skimage.morphology import disk\n",
    "\n",
    "dilated = morphology.binary_dilation(coins, disk(5))\n",
    "\n",
    "# dilation\n",
    "my_imshow(coins, title='original')\n",
    "plt.figure()\n",
    "my_imshow(dilated, title='dilated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eroded = morphology.binary_erosion(coins, disk(5))\n",
    "\n",
    "# erosion\n",
    "my_imshow(coins, title='original')\n",
    "plt.figure()\n",
    "my_imshow(eroded, title='eroded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opened = morphology.binary_opening(coins, disk(10))\n",
    "\n",
    "# opening\n",
    "my_imshow(coins, title='original')\n",
    "plt.figure()\n",
    "my_imshow(opened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closed = morphology.binary_closing(coins, disk(5))\n",
    "\n",
    "# closing\n",
    "my_imshow(coins, title='original')\n",
    "plt.figure()\n",
    "my_imshow(closed, title='closing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very helpful function for removing specks is the aptly-named `remove_small_objects`. For this mask, we first invert the mask (using python's not operator, `~`), remove the small objects, and then re-invert it so the background is black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_coin_mask = ~morphology.remove_small_objects(~coins, min_size=120)\n",
    "\n",
    "my_imshow(coins, cmap='gray', title='original mask')\n",
    "plt.figure()\n",
    "my_imshow(~coins, cmap='gray', title='inverted mask')\n",
    "plt.figure()\n",
    "my_imshow(clean_coin_mask, cmap='gray', title='clean mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "separated_coins = morphology.binary_erosion(closed, disk(20))\n",
    "labelled_coins = measure.label(separated_coins)\n",
    "\n",
    "my_imshow(separated_coins, title='separated coins')\n",
    "plt.figure()\n",
    "my_imshow(labelled_coins, cmap='jet', title='labelled coins')\n",
    "\n",
    "\n",
    "num_coins = len(np.unique(labelled_coins))-1  # subtract 1 b/c background is labelled 0\n",
    "print 'number of coins: %i' % num_coins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worked Example: Segmentation\n",
    "\n",
    "As an example of a typical image processing problem, we will segment the following image of bacteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = plt.imread('sample-images/caulobacter.png')\n",
    "print 'original image shape:', im.shape\n",
    "print 'alpha channel intensity: %.2f +- %.2f' % (np.mean(im[:,:,-1]), np.std(im[:,:,-1]))\n",
    "\n",
    "my_imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, convert from color (4 channel, actually) to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "\n",
    "# convert to gray \n",
    "gray_im = color.rgb2gray(im)\n",
    "print 'grayscale image shape:', gray_im.shape\n",
    "\n",
    "my_imshow(gray_im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blur slightly to reduce noise. (This isn't strictly necessary in this case, since it's a fairly high-quality image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "blurred_im = filters.gaussian_filter(gray_im, sigma=3)\n",
    "my_imshow(blurred_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the image is suitable pre-processed, we can threshold it to convert it to a cell mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh = 0.3\n",
    "mask = gray_im < thresh\n",
    "blurred_mask = blurred_im < thresh\n",
    "\n",
    "my_imshow(mask, title='mask from original grayscale image')\n",
    "my_imshow(blurred_mask, title='mask from blurred grayscale image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary images are manipulated with *morphological operations*. Morphological operations allow us to expand the white regions, shrink the white regions, fill in holes, and more. In this case, we simply want to remove the tiny dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "blurred_mask_clean = morphology.remove_small_objects(blurred_mask, min_size=150)\n",
    "\n",
    "my_imshow(blurred_mask_clean, title='blurred image mask with small object removed')\n",
    "my_imshow(blurred_mask - blurred_mask_clean, 'removed small objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the cells are touching, so they appear as one object, but we would like to identify them as separate objects. This is a very common problem in segmentation problems, noteably cell tracking. A common approach is to perform a *distance transform*, followed by a *watershed segmentation*.\n",
    "\n",
    "The distance transform converts a binary mask (black-and-white image) into a floating point image (grayscale image) of the same size. Each pixel in the distance transform represents the *distance of that pixel from the nearest black point in the mask*. Thus, the brighest points in the distance transform are the points that are furthest from object boundaries. An example will help clarify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "\n",
    "distance_im = ndi.distance_transform_edt(blurred_mask_clean)\n",
    "print 'distance transform:', distance_im.shape, distance_im.dtype\n",
    "\n",
    "my_imshow(distance_im, title='distance transform of mask')\n",
    "my_imshow(blurred_mask_clean[850:950, 300:400], title='mask showing 2 overlapping cells')\n",
    "my_imshow(distance_im[850:950, 300:400], title='distance transform of above')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we've done everything right, the peaks of the distance transform image represent the centers of each cell (including those that overlap). We label each separate peak with a unique integer with `skimage.measure.label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import feature, measure\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def imshow_overlay(im, mask, alpha=0.5, color='red', **kwargs):\n",
    "    \"\"\"Show semi-transparent red mask over an image\"\"\"\n",
    "    mask = mask > 0\n",
    "    mask = np.ma.masked_where(~mask, mask)        \n",
    "    plt.imshow(im, **kwargs)\n",
    "    plt.imshow(mask, alpha=alpha, cmap=ListedColormap([color]))\n",
    "\n",
    "\n",
    "peaks_im = feature.peak_local_max(distance_im, indices=False)\n",
    "\n",
    "plt.figure()\n",
    "imshow_overlay(distance_im[850:950, 300:400], peaks_im[850:950, 300:400], alpha=1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "random_colors = matplotlib.colors.ListedColormap (np.random.rand ( 256,3))\n",
    "\n",
    "\n",
    "markers_im = measure.label(peaks_im)\n",
    "labelled_cell_im = morphology.watershed(-distance_im, markers_im, mask=blurred_mask_clean)\n",
    "\n",
    "my_imshow(labelled_cell_im, 'labelled cells', cmap='jet')\n",
    "my_imshow(blurred_mask_clean[850:950, 300:400], 'mask of overlapping cells')\n",
    "my_imshow(labelled_cell_im[850:950, 300:400], 'labelled', cmap=random_colors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
